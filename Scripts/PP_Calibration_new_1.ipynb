{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Set the project path here\n",
    "PathProj = \"C:\\\\Users\\\\tepang\\\\Desktop\\\\Test3\"\n",
    "sys.path.append(PathProj)\n",
    "\n",
    "from Calibration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPdispatchError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_period(t_from=PERIOD_FROM, t_to=PERIOD_TO)\n",
    "set_scenario({'sys demand': 'Baseline'})\n",
    "\n",
    "Results = solve(simulation_name='Baseline', runchecks=False, daily_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Running Calibration Module (if required)\n",
    "- skip this step if user is satisfied with the results generated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color=#117A65>2.1) Pre-Calibration</font></i></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Run Pre-Calibration, need at least 2 runs to get a valid std result\n",
    "\n",
    "prepare_save_file(path.join(PATHS['Proj'],'Scripts\\\\In_Progress\\\\pre-calibration_in_progress.csv'))\n",
    "Pre_Calibration(2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color=#117A65>2.2) Normalize Parameters</font></i></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Normalize Parameters\n",
    "\n",
    "# Load the Pre-Calibration file\n",
    "filename=path.join(PATHS['Proj'],'Scripts\\\\In_Progress\\\\pre-calibration_in_progress.csv')\n",
    "data = pd.read_csv(filename, index_col=[0])\n",
    "data.to_csv(path.join(PATHS['Proj'],'Scripts\\\\pre-calibration.csv'), index=True)\n",
    "print('Pre-Calibration file transferred complete')\n",
    "\n",
    "# PRE_CALIBRATE_PARAMS = pd.read_csv(path.join(PATHS['Proj'],'Scripts\\\\pre-calibration.csv'),index_col=[0]) \n",
    "# Use PRE_CALIBRATE_PARAMS to calculate normalize values\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color=#117A65>2.3) Calibration</font></i></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Run Calibration\n",
    "# Need to calculate normalize values before running Calibration\n",
    "max_evals = 500\n",
    "\n",
    "File_in_progress = path.join(PATHS['Proj'],'Scripts\\\\In_Progress\\\\calibration_in_progress.csv')\n",
    "prepare_save_file(File_in_progress)\n",
    "best, PARAMS_DFS, RANDSEEDS_DFS  = Calibration(max_evals,File_in_progress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Best Score\n",
    "# display_run_score(RUN) # RUN is the run no. in excel\n",
    "# display_run_score(trials.best_trial['tid']+1)\n",
    "# best = trials.best_trial['tid']+1\n",
    "display_run_score(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running with Best Parameters\n",
    "import gd_core as __core\n",
    "\n",
    "PPdb['params'] = PARAMS_DFS[best-1].copy()\n",
    "PPdb['randseeds'] = RANDSEEDS_DFS[best-1].copy()\n",
    "\n",
    "__core.reinit_fleet()\n",
    "\n",
    "Results = solve(simulation_name='Baseline', runchecks=False, daily_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online capacities (baseline)\n",
    "plot_OnlineCapacity(Results, ppclasses='default') #ppclasses='default','total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fuelmix(Results,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Generation of AH required for WRF input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_allheat(Results)\n",
    "compiled_prms = thermal_analysis(GenFleet, dParameters)\n",
    "\n",
    "calc_heatstreams1(GenFleet, Results, by='outlet',)\n",
    "calc_heatstreams1(GenFleet, Results, by='kind', latentheatfactors=dParameters['latent heat factors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the WRF input files for a day\n",
    "# unit options 'W/m^2' 'MW'\n",
    "\n",
    "WRF_SH, WRF_LH, WRF_Sea, total_MWh = prep_WRF_inputs(\n",
    "    scenario='Test WRF - 2016 Apr (3)', \n",
    "    GenFleet=GenFleet, \n",
    "    PPcells_only=False,   # Set to False if you want the full grid (sparse)\n",
    "    With_height=True,\n",
    "    unit='MW',\n",
    "    day='2016 Apr 15', \n",
    "    write_to_disk = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
